I am process 29786, running on gpu06: starting (Sat Mar  5 11:12:17 2022)
args.batch_size 8
args Namespace(a_imagenet_pretrain=True, a_patch_num=256, audioset_pretrain=False, bal=None, batch_size=8, data_eval='test_iemocap_dataset.json', data_train='train_iemocap_dataset.json', data_val='valid_iemocap_dataset.json', dataset='iemocap', early_stop=5, exp_dir='model_dir/temp_imagenet_8_0.0001_40_fusion', face_size=128, freqm=0, fstride=16, k=-1, label_csv='', lr=0.0001, lr_patience=2, mixup=0, modal='tav', model='ast_models_video_deit_transformer_freeze', n_class=6, n_epochs=40, n_print_steps=100, num_height=384, num_width=384, num_workers=12, optim='adam', save_model=None, scale=0, seed=1234, text_lr_factor=100, text_max_len=300, time_dim_split=True, timem=0, tstride=16, v_imagenet_pretrain=True, v_patch_num=256)
now process iemocap
---------------the train dataloader---------------
number of classes is 6
now process iemocap
---------------the evaluation dataloader---------------
number of classes is 6
---------------AST Model Summary---------------
ImageNet pretraining: True, AudioSet pretraining: False
frequncey stride=16, time stride=16
number of patches=512
---------------AST Model Summary---------------
ImageNet pretraining: True, AudioSet pretraining: False
frequncey stride=16, time stride=16
number of patches=256
Creating experiment directory: model_dir/temp_imagenet_8_0.0001_40_fusion
Now starting training for 40 epochs
running on cuda
Some weights of the model checkpoint at /users10/zyzhang/graduationProject/data/pretrain_model/bert_base_uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Total parameter number is : 305.026 million
Total trainable parameter number is : 20.726 million
scheduler for iemocap is used
now training with iemocap, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f1a19458090>
current #steps=0, #epochs=1
start training...
---------------
2022-03-05 11:12:59.761584
current #epochs=1, #steps=0
Epoch: [1][100/646]	Per Sample Total Time 0.09027	Per Sample Data Time 0.01624	Per Sample DNN Time 0.07402	Train Loss 0.4631	
Epoch: [1][200/646]	Per Sample Total Time 0.08561	Per Sample Data Time 0.01163	Per Sample DNN Time 0.07398	Train Loss 0.4393	
Epoch: [1][300/646]	Per Sample Total Time 0.09110	Per Sample Data Time 0.01711	Per Sample DNN Time 0.07399	Train Loss 0.4266	
Error in sys.excepthook:
Traceback (most recent call last):
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/tokenize.py", line 449, in open
    encoding, lines = detect_encoding(buffer.readline)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/tokenize.py", line 418, in detect_encoding
    first = read_or_stop()
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/tokenize.py", line 376, in read_or_stop
    return readline()
KeyboardInterrupt
Original exception was:
Traceback (most recent call last):
  File "run.py", line 277, in <module>
    train(mt_model, train_loader, val_loader, args, tokenizer_model)
  File "/users10/zyzhang/multimodel/E2EMMT_interact/traintest.py", line 132, in train
    tav_output = mmt_model(audio_input, video_input, text_input)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 166, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py", line 141, in decorate_autocast
    return func(*args, **kwargs)
  File "/users10/zyzhang/multimodel/E2EMMT_interact/models/ast_models_video_deit_transformer_freeze.py", line 343, in forward
    video_last_hidden_state, video_pooler_output, video_hidden_states = self.video_model(video_input)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py", line 141, in decorate_autocast
    return func(*args, **kwargs)
  File "/users10/zyzhang/multimodel/E2EMMT_interact/models/ast_models_video_deit_transformer_freeze.py", line 232, in forward
    x = blk(x)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/timm/models/vision_transformer.py", line 198, in forward
    x = x + self.drop_path(self.attn(self.norm1(x)))
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/timm/models/vision_transformer.py", line 170, in forward
    qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 96, in forward
    return F.linear(input, self.weight, self.bias)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/functional.py", line 1847, in linear
    return torch._C._nn.linear(input, weight, bias)
KeyboardInterrupt