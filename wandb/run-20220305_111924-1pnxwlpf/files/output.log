I am process 31118, running on gpu06: starting (Sat Mar  5 11:19:31 2022)
args.batch_size 8
args Namespace(a_imagenet_pretrain=True, a_patch_num=256, audioset_pretrain=False, bal=None, batch_size=8, data_eval='test_iemocap_dataset.json', data_train='train_iemocap_dataset.json', data_val='valid_iemocap_dataset.json', dataset='iemocap', early_stop=5, exp_dir='model_dir/temp_imagenet_8_0.0001_40_fusion', face_size=128, freqm=0, fstride=16, k=-1, label_csv='', lr=0.0001, lr_patience=2, mixup=0, modal='tav', model='ast_model_video_deit', n_class=6, n_epochs=40, n_print_steps=100, num_height=384, num_width=384, num_workers=12, optim='adam', save_model=None, scale=0, seed=1234, text_lr_factor=100, text_max_len=300, time_dim_split=True, timem=0, tstride=16, v_imagenet_pretrain=True, v_patch_num=256)
now process iemocap
---------------the train dataloader---------------
number of classes is 6
now process iemocap
---------------the evaluation dataloader---------------
number of classes is 6
---------------AST Model Summary---------------
ImageNet pretraining: True, AudioSet pretraining: False
frequncey stride=16, time stride=16
number of patches=512
---------------AST Model Summary---------------
ImageNet pretraining: True, AudioSet pretraining: False
frequncey stride=16, time stride=16
number of patches=256
Creating experiment directory: model_dir/temp_imagenet_8_0.0001_40_fusion
Now starting training for 40 epochs
running on cuda
Some weights of the model checkpoint at /users10/zyzhang/graduationProject/data/pretrain_model/bert_base_uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Total parameter number is : 305.026 million
Total trainable parameter number is : 305.026 million
scheduler for iemocap is used
now training with iemocap, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fb9aba96150>
current #steps=0, #epochs=1
start training...
---------------
2022-03-05 11:19:41.618172
current #epochs=1, #steps=0
Traceback (most recent call last):
  File "run.py", line 277, in <module>
    train(mt_model, train_loader, val_loader, args, tokenizer_model)
  File "/users10/zyzhang/multimodel/E2EMMT_interact/traintest.py", line 132, in train
    tav_output = mmt_model(audio_input, video_input, text_input)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 166, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py", line 141, in decorate_autocast
    return func(*args, **kwargs)
  File "/users10/zyzhang/multimodel/E2EMMT_interact/models/ast_models_video_deit.py", line 337, in forward
    audio_hidden_states = self.audio_model(audio_input)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py", line 141, in decorate_autocast
    return func(*args, **kwargs)
  File "/users10/zyzhang/multimodel/E2EMMT_interact/models/ast_models_video_deit.py", line 127, in forward
    x = blk(x)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/timm/models/vision_transformer.py", line 198, in forward
    x = x + self.drop_path(self.attn(self.norm1(x)))
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users10/zyzhang/anaconda3/envs/SparseEnd2End/lib/python3.7/site-packages/timm/models/vision_transformer.py", line 174, in forward
    attn = attn.softmax(dim=-1)
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 11.91 GiB total capacity; 10.72 GiB already allocated; 64.94 MiB free; 11.00 GiB reserved in total by PyTorch)